{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df31776",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path = r\"C:\\Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f769bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ZIP extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = r\"C:\\Users\\BHUVANA VIJAYA\\Downloads\\Dataset.zip\"\n",
    "extract_path = r\"C:\\Dataset\"  # much shorter path\n",
    "\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"✅ ZIP extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4451e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e22b0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 639 PDF files in dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  22%|██▏       | 141/639 [00:08<00:31, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: library error: FT_New_Memory_Face(Times-Bold): unknown file format\n",
      "\n",
      "MuPDF error: library error: FT_New_Memory_Face(Times-Bold): unknown file format\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 639/639 [00:43<00:00, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extraction complete! Total authors processed: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "\n",
    "# Path to your extracted dataset\n",
    "DATASET_PATH = Path(r\"C:\\Dataset\")  # change to your folder\n",
    "\n",
    "# Check if path exists\n",
    "if not DATASET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset path not found: {DATASET_PATH}\")\n",
    "\n",
    "author_texts = {}\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9.,:;!?()\\-\\'\"\\s]', '', text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "# Determine if Windows long path prefix is needed\n",
    "WINDOWS = platform.system() == \"Windows\"\n",
    "\n",
    "# Recursive scan for PDFs\n",
    "all_pdf_files = list(DATASET_PATH.rglob(\"*.pdf\"))\n",
    "print(f\"Found {len(all_pdf_files)} PDF files in dataset.\")\n",
    "\n",
    "for pdf_file in tqdm(all_pdf_files, desc=\"Processing PDFs\"):\n",
    "    author_name = pdf_file.parent.name  # folder containing PDF\n",
    "    file_path = str(pdf_file)\n",
    "\n",
    "    # Add long path prefix for Windows if needed\n",
    "    if WINDOWS:\n",
    "        file_path = \"\\\\\\\\?\\\\\" + file_path\n",
    "\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with fitz.open(file_path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text(\"text\")\n",
    "        clean = clean_text(text)\n",
    "        if len(clean) > 200:  # ignore very short PDFs\n",
    "            author_texts.setdefault(author_name, []).append(clean)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {file_path}: {e}\")\n",
    "\n",
    "# Save JSON\n",
    "output_path = DATASET_PATH / \"author_texts.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(author_texts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Extraction complete! Total authors processed: {len(author_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b09732da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors: 71\n",
      "Sample author names: ['Amit Saxena', 'Amita Jain', 'Animesh Chaturvedi', 'Ankita Jain', 'Arun Chauhan']\n",
      "\n",
      "Preview of first paper for Amit Saxena:\n",
      "\n",
      "a review of clustering techniques and developments amit saxena1, mukesh prasad2, akshansh gupta3, neha bharill4, om prakash patel4, aruna tiwari4, meng joo er5, weiping ding6, chin-teng lin2 1department of computer science  it, guru ghasidas vishwavidyalaya, bilaspur, india 2centre for artificial intelligence, university of technology sydney, sydney, australia 3school of computational and integrative sciences, jawaharlal nehru university, new delhi, india 4department of computer science and engi\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Path to the JSON file\n",
    "json_path = r\"C:\\Dataset\\author_texts.json\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(json_path):\n",
    "    raise FileNotFoundError(f\"JSON file not found at {json_path}\")\n",
    "\n",
    "# Load JSON\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Check if JSON is empty\n",
    "if not data:\n",
    "    print(\"⚠️ The JSON file is empty. No authors found.\")\n",
    "else:\n",
    "    print(f\"Total authors: {len(data)}\")\n",
    "    sample_authors = list(data.keys())[:5]\n",
    "    print(\"Sample author names:\", sample_authors)\n",
    "\n",
    "    # Preview first 500 characters of the first paper of the first author\n",
    "    first_author = sample_authors[0]\n",
    "    if data[first_author]:\n",
    "        print(f\"\\nPreview of first paper for {first_author}:\\n\")\n",
    "        print(data[first_author][0][:500])\n",
    "    else:\n",
    "        print(f\"No papers found for {first_author}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
