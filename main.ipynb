{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79624cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amit Saxena: 0.0022\n",
      "Amita Jain: 0.0000\n",
      "Animesh Chaturvedi: 0.0051\n",
      "Ankita Jain: 0.0098\n",
      "Arun Chauhan: 0.0045\n",
      "Aruna Malapati: 0.0078\n",
      "Aruna Tiwari: 0.0058\n",
      "Barsha Mitra: 0.0008\n",
      "Bhanukiran Perabathini: 0.0053\n",
      "Bharghava Rajaram: 0.0010\n",
      "Deepak K T: 0.0224\n",
      "Devendra K Tayal: 0.0484\n",
      "Dilip Singh Sisodia: 0.0219\n",
      "dipanjan roy: 0.0016\n",
      "Dipti Mishra: 0.0009\n",
      "Dr. Ashish Jain: 0.0323\n",
      "Dr. Shikha Mehta: 0.0263\n",
      "Dr.Manpreet Kaur: 0.0004\n",
      "Dr.Rohit Beniwal: 0.0074\n",
      "Dr.Ruchi Mittal: 0.0116\n",
      "esha baidya kayal: 0.0000\n",
      "Geeta Rani: 0.0008\n",
      "Himanee Bansal: 0.0460\n",
      "Himanshu Mittal: 0.0459\n",
      "J. Balasubramaniam: 0.0013\n",
      "Jagdish Bansal: 0.0692\n",
      "Jayasri D: 0.0000\n",
      "Jian Wang: 0.0010\n",
      "K.V. Sambasivarao: 0.0029\n",
      "Kastuv Nag: 0.0203\n",
      "Khaldoon Dhou: 0.0152\n",
      "Krishna Asawa: 0.1024\n",
      "Mala Saraswat: 0.0256\n",
      "Manju_JaypeeTech: 0.0029\n",
      "Manoranjan Mohanty: 0.0244\n",
      "Minni Jain: 0.0041\n",
      "Mukesh Prasad: 0.0142\n",
      "Navneet Pratap Singh: 0.0047\n",
      "Nikhil Tripathi: 0.0062\n",
      "Nishchal K. Verma: 0.0000\n",
      "Om Prakash Patel: 0.0125\n",
      "OmPrakash Kaiwartya: 0.0042\n",
      "Pabitra Mitra: 0.0061\n",
      "Payal Khurana Batra: 0.0000\n",
      "Pinaki Chakraborty: 0.0204\n",
      "Prakash Chandra Sharma: 0.0464\n",
      "Prof. B Subudhi: 0.0146\n",
      "Rama Murthy Garimella: 0.0055\n",
      "Ramakrishan Maheshwari: 0.0000\n",
      "Ramalinga Swamy Cheruku: 0.0345\n",
      "ruchi sharma: 0.0018\n",
      "Rudresh dwivedi: 0.0408\n",
      "Sambit Bakshi: 0.0106\n",
      "Sanatan Sukhija: 0.0052\n",
      "Shikha Gupta: 0.0216\n",
      "Sowmini Devi: 0.0028\n",
      "Sreedhar Madichetty: 0.0005\n",
      "Srishti Sharma: 0.0009\n",
      "Sulabh Tyagi: 0.0036\n",
      "Sunny Rai: 0.0024\n",
      "sushma hans: 0.0055\n",
      "Tandra Pal: 0.0118\n",
      "Tingwen Huang: 0.0043\n",
      "Udit Satija: 0.0127\n",
      "V. Ravi: 0.0044\n",
      "Vaishali Soni: 0.0000\n",
      "Venkata Dilip Kumar: 0.0035\n",
      "Venkata Rajesh Kumar Tavva: 0.0093\n",
      "Vidhi Khanduja: 0.0044\n",
      "Yayati Gupta: 0.0034\n",
      "Yew-Soon Ong: 0.0801\n"
     ]
    }
   ],
   "source": [
    "#lexion keyword matching\n",
    "#Method: Extract keywords from each authorâ€™s papers and the input paper, then compute overlap.\n",
    "#Pros: Fast, interpretable, easy to implement.\n",
    "#Cons: Sensitive to vocabulary mismatch, ignores context or semantic meaning.\n",
    "#Use case: Works if papers have a very specific jargon or limited domain.\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"author_texts_pdfminer.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    authors_json = json.load(f)\n",
    "\n",
    "# Example query\n",
    "query_text = \"your search query here\"\n",
    "\n",
    "# Join all papers of each author into a single string\n",
    "all_texts = [\" \".join(author_papers) for author_papers in authors_json.values()]\n",
    "\n",
    "# Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(all_texts)\n",
    "query_vec = vectorizer.transform([query_text])\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(query_vec, X)\n",
    "\n",
    "# Print similarity scores\n",
    "for author, score in zip(authors_json.keys(), cosine_sim[0]):\n",
    "    print(f\"{author}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe37be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amit Saxena: 0.0181\n",
      "Amita Jain: 0.0000\n",
      "Animesh Chaturvedi: 0.0000\n",
      "Ankita Jain: 0.3823\n",
      "Arun Chauhan: 0.0000\n",
      "Aruna Malapati: 0.2067\n",
      "Aruna Tiwari: 0.6036\n",
      "Barsha Mitra: 0.0031\n",
      "Bhanukiran Perabathini: 0.0182\n",
      "Bharghava Rajaram: 0.0000\n",
      "Deepak K T: 0.2714\n",
      "Devendra K Tayal: 0.2875\n",
      "Dilip Singh Sisodia: 0.3650\n",
      "dipanjan roy: 0.0094\n",
      "Dipti Mishra: 0.0162\n",
      "Dr. Ashish Jain: 0.7426\n",
      "Dr. Shikha Mehta: 0.6932\n",
      "Dr.Manpreet Kaur: 0.2117\n",
      "Dr.Rohit Beniwal: 0.0000\n",
      "Dr.Ruchi Mittal: 0.0891\n",
      "esha baidya kayal: 0.0000\n",
      "Geeta Rani: 0.0065\n",
      "Himanee Bansal: 0.3044\n",
      "Himanshu Mittal: 0.5837\n",
      "J. Balasubramaniam: 0.0000\n",
      "Jagdish Bansal: 0.7953\n",
      "Jayasri D: 0.0000\n",
      "Jian Wang: 0.0823\n",
      "K.V. Sambasivarao: 0.4543\n",
      "Kastuv Nag: 0.6941\n",
      "Khaldoon Dhou: 0.0075\n",
      "Krishna Asawa: 0.3509\n",
      "Mala Saraswat: 0.2092\n",
      "Manju_JaypeeTech: 0.0000\n",
      "Manoranjan Mohanty: 0.3758\n",
      "Minni Jain: 0.0030\n",
      "Mukesh Prasad: 0.4196\n",
      "Navneet Pratap Singh: 0.1345\n",
      "Nikhil Tripathi: 0.0369\n",
      "Nishchal K. Verma: 0.3153\n",
      "Om Prakash Patel: 0.6893\n",
      "OmPrakash Kaiwartya: 0.0369\n",
      "Pabitra Mitra: 0.0000\n",
      "Payal Khurana Batra: 0.0000\n",
      "Pinaki Chakraborty: 0.0482\n",
      "Prakash Chandra Sharma: 0.6103\n",
      "Prof. B Subudhi: 0.2298\n",
      "Rama Murthy Garimella: 0.0273\n",
      "Ramakrishan Maheshwari: 0.0000\n",
      "Ramalinga Swamy Cheruku: 0.6570\n",
      "ruchi sharma: 0.0380\n",
      "Rudresh dwivedi: 0.3788\n",
      "Sambit Bakshi: 0.6321\n",
      "Sanatan Sukhija: 0.0596\n",
      "Shikha Gupta: 0.4390\n",
      "Sowmini Devi: 0.0000\n",
      "Sreedhar Madichetty: 0.0000\n",
      "Srishti Sharma: 0.0302\n",
      "Sulabh Tyagi: 0.0000\n",
      "Sunny Rai: 0.0000\n",
      "sushma hans: 0.0000\n",
      "Tandra Pal: 0.1231\n",
      "Tingwen Huang: 0.1584\n",
      "Udit Satija: 0.0735\n",
      "V. Ravi: 0.4630\n",
      "Vaishali Soni: 0.0000\n",
      "Venkata Dilip Kumar: 0.2251\n",
      "Venkata Rajesh Kumar Tavva: 0.0000\n",
      "Vidhi Khanduja: 0.0019\n",
      "Yayati Gupta: 0.0000\n",
      "Yew-Soon Ong: 0.7001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BHUVANA VIJAYA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1728: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Topic Modeling (LDA / NMF)\n",
    "#Method: Represent each paper in terms of topics instead of individual words.\n",
    "#Pros: Captures underlying research themes, good for interdisciplinarity.\n",
    "#Cons: Needs careful tuning (number of topics), may lose fine-grained differences.\n",
    "#Use case: Useful when papers cover multiple areas or if you want topic-based clustering of reviewers.*/\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Combine all papers of each author\n",
    "all_texts = [\" \".join(papers) for papers in authors_json.values()]\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X = tfidf.fit_transform(all_texts)\n",
    "\n",
    "# NMF topic modeling\n",
    "nmf = NMF(n_components=20, random_state=42)\n",
    "W = nmf.fit_transform(X)  # Each author represented by topic vector\n",
    "\n",
    "# Transform the query paper\n",
    "query_W = nmf.transform(tfidf.transform([query_text]))\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(query_W, W).flatten()  # flatten to 1D array\n",
    "\n",
    "# Print author similarities\n",
    "for author, score in zip(authors_json.keys(), cosine_sim):\n",
    "    print(f\"{author}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1452570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight and fast\n",
    "\n",
    "# Encode all authors' papers\n",
    "author_names = list(authors_json.keys())\n",
    "author_embeddings = [model.encode(\" \".join(authors_json[author]), convert_to_tensor=True) \n",
    "                     for author in author_names]\n",
    "\n",
    "# Encode query paper\n",
    "query_embedding = model.encode(query_text, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine similarity scores\n",
    "cos_scores = [util.cos_sim(query_embedding, emb).item() for emb in author_embeddings]\n",
    "\n",
    "# Print authors with their similarity scores\n",
    "for author, score in zip(author_names, cos_scores):\n",
    "    print(f\"{author}: {score:.4f}\")\n",
    "\n",
    "# Optional: Top-k authors\n",
    "k = 5\n",
    "top_indices = sorted(range(len(cos_scores)), key=lambda i: cos_scores[i], reverse=True)[:k]\n",
    "print(\"\\nTop-k recommended reviewers:\")\n",
    "for i in top_indices:\n",
    "    print(f\"{author_names[i]}: {cos_scores[i]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
